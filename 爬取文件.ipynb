{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**开始爬取->剧情<-类型的电影**\n",
      "开始爬取电影《肖申克的救赎》的影评...\n",
      "电影《肖申克的救赎》的影评爬取完毕\n",
      "开始爬取电影《霸王别姬》的影评...\n",
      "电影《霸王别姬》的影评爬取完毕\n",
      "**开始爬取->喜剧<-类型的电影**\n",
      "开始爬取电影《美丽人生》的影评...\n",
      "电影《美丽人生》的影评爬取完毕\n",
      "开始爬取电影《鬼子来了》的影评...\n",
      "电影《鬼子来了》的影评爬取完毕\n",
      "**开始爬取->动作<-类型的电影**\n",
      "开始爬取电影《这个杀手不太冷》的影评...\n",
      "电影《这个杀手不太冷》的影评爬取完毕\n",
      "开始爬取电影《指环王3：王者无敌》的影评...\n",
      "电影《指环王3：王者无敌》的影评爬取完毕\n",
      "**开始爬取->爱情<-类型的电影**\n",
      "开始爬取电影《霸王别姬》的影评...\n",
      "电影《霸王别姬》的影评爬取完毕\n",
      "开始爬取电影《泰坦尼克号》的影评...\n",
      "电影《泰坦尼克号》的影评爬取完毕\n",
      "**开始爬取->科幻<-类型的电影**\n",
      "开始爬取电影《盗梦空间》的影评...\n",
      "电影《盗梦空间》的影评爬取完毕\n",
      "开始爬取电影《星际穿越》的影评...\n",
      "电影《星际穿越》的影评爬取完毕\n",
      "**开始爬取->动画<-类型的电影**\n",
      "开始爬取电影《千与千寻》的影评...\n",
      "电影《千与千寻》的影评爬取完毕\n",
      "开始爬取电影《大闹天宫》的影评...\n",
      "电影《大闹天宫》的影评爬取完毕\n",
      "**开始爬取->悬疑<-类型的电影**\n",
      "开始爬取电影《控方证人》的影评...\n",
      "电影《控方证人》的影评爬取完毕\n",
      "开始爬取电影《盗梦空间》的影评...\n",
      "电影《盗梦空间》的影评爬取完毕\n",
      "**开始爬取->惊悚<-类型的电影**\n",
      "开始爬取电影《无间道》的影评...\n",
      "电影《无间道》的影评爬取完毕\n",
      "开始爬取电影《蝙蝠侠：黑暗骑士》的影评...\n",
      "电影《蝙蝠侠：黑暗骑士》的影评爬取完毕\n",
      "**开始爬取->恐怖<-类型的电影**\n",
      "开始爬取电影《惊魂记》的影评...\n",
      "电影《惊魂记》的影评爬取完毕\n",
      "开始爬取电影《电锯惊魂》的影评...\n",
      "电影《电锯惊魂》的影评爬取完毕\n",
      "**开始爬取->纪录片<-类型的电影**\n",
      "开始爬取电影《蒙古草原，天气晴》的影评...\n",
      "电影《蒙古草原，天气晴》的影评爬取完毕\n",
      "开始爬取电影《三十二》的影评...\n",
      "电影《三十二》的影评爬取完毕\n",
      "**开始爬取->短片<-类型的电影**\n",
      "开始爬取电影《鹬》的影评...\n",
      "电影《鹬》的影评爬取完毕\n",
      "开始爬取电影《回忆积木小屋》的影评...\n",
      "电影《回忆积木小屋》的影评爬取完毕\n",
      "**开始爬取->情色<-类型的电影**\n",
      "开始爬取电影《西西里的美丽传说》的影评...\n",
      "电影《西西里的美丽传说》的影评爬取完毕\n",
      "开始爬取电影《色，戒》的影评...\n",
      "电影《色，戒》的影评爬取完毕\n",
      "**开始爬取->音乐<-类型的电影**\n",
      "开始爬取电影《海上钢琴师》的影评...\n",
      "电影《海上钢琴师》的影评爬取完毕\n",
      "开始爬取电影《放牛班的春天》的影评...\n",
      "电影《放牛班的春天》的影评爬取完毕\n",
      "**开始爬取->歌舞<-类型的电影**\n",
      "开始爬取电影《三傻大闹宝莱坞》的影评...\n",
      "电影《三傻大闹宝莱坞》的影评爬取完毕\n",
      "开始爬取电影《狮子王》的影评...\n",
      "电影《狮子王》的影评爬取完毕\n",
      "**开始爬取->家庭<-类型的电影**\n",
      "开始爬取电影《活着》的影评...\n",
      "电影《活着》的影评爬取完毕\n",
      "开始爬取电影《海蒂和爷爷》的影评...\n",
      "电影《海蒂和爷爷》的影评爬取完毕\n",
      "**开始爬取->儿童<-类型的电影**\n",
      "开始爬取电影《小鞋子》的影评...\n",
      "电影《小鞋子》的影评爬取完毕\n",
      "开始爬取电影《天堂回信》的影评...\n",
      "电影《天堂回信》的影评爬取完毕\n",
      "**开始爬取->传记<-类型的电影**\n",
      "开始爬取电影《末代皇帝》的影评...\n",
      "电影《末代皇帝》的影评爬取完毕\n",
      "开始爬取电影《钢琴家》的影评...\n",
      "电影《钢琴家》的影评爬取完毕\n",
      "**开始爬取->历史<-类型的电影**\n",
      "开始爬取电影《茶馆》的影评...\n",
      "电影《茶馆》的影评爬取完毕\n",
      "开始爬取电影《辛德勒的名单》的影评...\n",
      "电影《辛德勒的名单》的影评爬取完毕\n",
      "**开始爬取->战争<-类型的电影**\n",
      "开始爬取电影《美丽人生》的影评...\n",
      "电影《美丽人生》的影评爬取完毕\n",
      "开始爬取电影《辛德勒的名单》的影评...\n",
      "电影《辛德勒的名单》的影评爬取完毕\n",
      "**开始爬取->犯罪<-类型的电影**\n",
      "开始爬取电影《肖申克的救赎》的影评...\n",
      "电影《肖申克的救赎》的影评爬取完毕\n",
      "开始爬取电影《控方证人》的影评...\n",
      "电影《控方证人》的影评爬取完毕\n",
      "**开始爬取->西部<-类型的电影**\n",
      "开始爬取电影《黄金三镖客》的影评...\n",
      "电影《黄金三镖客》的影评爬取完毕\n",
      "开始爬取电影《淘金记》的影评...\n",
      "电影《淘金记》的影评爬取完毕\n",
      "**开始爬取->奇幻<-类型的电影**\n",
      "开始爬取电影《千与千寻》的影评...\n",
      "电影《千与千寻》的影评爬取完毕\n",
      "开始爬取电影《大闹天宫》的影评...\n",
      "电影《大闹天宫》的影评爬取完毕\n",
      "**开始爬取->冒险<-类型的电影**\n",
      "开始爬取电影《盗梦空间》的影评...\n",
      "电影《盗梦空间》的影评爬取完毕\n",
      "开始爬取电影《星际穿越》的影评...\n",
      "电影《星际穿越》的影评爬取完毕\n",
      "**开始爬取->灾难<-类型的电影**\n",
      "开始爬取电影《泰坦尼克号》的影评...\n",
      "电影《泰坦尼克号》的影评爬取完毕\n",
      "开始爬取电影《釜山行》的影评...\n",
      "电影《釜山行》的影评爬取完毕\n",
      "**开始爬取->武侠<-类型的电影**\n",
      "开始爬取电影《倩女幽魂》的影评...\n",
      "电影《倩女幽魂》的影评爬取完毕\n",
      "开始爬取电影《射雕英雄传之东成西就》的影评...\n",
      "电影《射雕英雄传之东成西就》的影评爬取完毕\n",
      "**开始爬取->古装<-类型的电影**\n",
      "开始爬取电影《大闹天宫》的影评...\n",
      "电影《大闹天宫》的影评爬取完毕\n",
      "开始爬取电影《大话西游之大圣娶亲》的影评...\n",
      "电影《大话西游之大圣娶亲》的影评爬取完毕\n",
      "**开始爬取->运动<-类型的电影**\n",
      "开始爬取电影《摔跤吧！爸爸》的影评...\n",
      "电影《摔跤吧！爸爸》的影评爬取完毕\n",
      "开始爬取电影《灌篮高手》的影评...\n",
      "电影《灌篮高手》的影评爬取完毕\n",
      "**开始爬取->黑色电影<-类型的电影**\n",
      "开始爬取电影《日落大道》的影评...\n",
      "电影《日落大道》的影评爬取完毕\n",
      "开始爬取电影《杀手》的影评...\n",
      "电影《杀手》的影评爬取完毕\n",
      "所有电影的影评已爬取并保存至all_movie_comments.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "\n",
    "# UA伪装\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36',\n",
    "\n",
    "}\n",
    "\n",
    "# 主网页\n",
    "url = 'https://movie.douban.com/chart'\n",
    "\n",
    "# 设置代理,\n",
    "proxies = {\n",
    "    \n",
    "    'http': \"49.233.242.15:5000\",  # 豆瓣ip（doge，想不到吧）\n",
    "    \n",
    "}\n",
    "\n",
    "# 解决乱码问题\n",
    "response = requests.get(url, headers=headers, proxies=proxies)\n",
    "response.encoding = 'utf-8'\n",
    "\n",
    "# 获得不同类型电影的url\n",
    "response = response.text\n",
    "main_soup = BeautifulSoup(response, 'html.parser')\n",
    "dif_movies = main_soup.select('#content > div > div.aside > div:nth-child(1) > div')\n",
    "movie_types = []  # 存储不同类型电影的页面url\n",
    "urls = dif_movies[0].find_all('a')\n",
    "\n",
    "# 获得不同类型电影的代号和名称\n",
    "for url in urls:\n",
    "    param = url['href']\n",
    "    index1 = param.find(\"&type=\")\n",
    "    index2 = param.find(\"&interval_id=\")\n",
    "    type_num = param[index1 + 6:index2]  # 电影类型代号\n",
    "    type_name = param[20:index1]  # 电影类型名称\n",
    "    movie_types.append((type_num, type_name))\n",
    "\n",
    "# 爬取不同类型电影中前15的电影评论\n",
    "for type, movie_class in movie_types:\n",
    "    print(f\"{'*' * 2}开始爬取->{movie_class}<-类型的电影{'*' * 2}\")\n",
    "\n",
    "    movie_url = 'https://movie.douban.com/j/chart/top_list'\n",
    "    param = {\n",
    "        \"start\": \"0\",\n",
    "        \"limit\": \"2\",\n",
    "        \"type\": f\"{type}\",\n",
    "        \"interval_id\": \"100:90\",\n",
    "        \"action\": \"\",\n",
    "\n",
    "    }\n",
    "    response = requests.get(movie_url, headers=headers, params=param, proxies=proxies)\n",
    "    time.sleep(1)  # 限制请求时间，防止被封ip\n",
    "    response.encoding = 'utf-8'\n",
    "    movie_data = response.json()\n",
    "\n",
    "    # 存放这个类型下前二十的电影的网址和名称\n",
    "    urls = []\n",
    "    for data in movie_data:\n",
    "        urls.append((data['url'], data['title']))\n",
    "\n",
    "    all_comments_file = 'C:/Users/86187/Desktop/yingpin/all_movie_comments.txt'  \n",
    "  \n",
    " \n",
    "    os.makedirs(os.path.dirname(all_comments_file), exist_ok=True)  \n",
    "  \n",
    "# 爬取每一部电影前10页的电影评论，共计200条  \n",
    "    with open(all_comments_file, 'w', encoding='utf-8') as f_all_comments:  \n",
    "        for url in urls:  \n",
    "            print(f\"开始爬取电影《{url[1]}》的影评...\")  \n",
    "          \n",
    "        # 获得这部电影下前十页的影评网址  \n",
    "            comment_urls = []  \n",
    "            head_url = url[0] + 'comments?limit=20&status=P&sort=new_score'  # 影评网址首页  \n",
    "            comment_urls.append(head_url)  \n",
    "            for i in range(20, 201, 20):  \n",
    "                other_url = url[0] + f\"comments?start={i}&limit=20&status=P&sort=new_score\"  \n",
    "                comment_urls.append(other_url)  # 后续9个影评网页  \n",
    "  \n",
    "        # 爬取所有的影评  \n",
    "            for comment_url in comment_urls:  \n",
    "                response = requests.get(comment_url, headers=headers, proxies=proxies)  \n",
    "                time.sleep(1)  # 限制次数，防止被封ip  \n",
    "                response.encoding = 'utf-8'  \n",
    "                response_text = response.text  \n",
    "  \n",
    "            # 定位到评论所在的地方  \n",
    "                soup = BeautifulSoup(response_text, 'html.parser')  \n",
    "                comments = soup.select(\"#comments\")  \n",
    "                try:  \n",
    "                     comments_ = comments[0].find_all(\"span\", class_='short')  \n",
    "                except IndexError:  \n",
    "                     continue  \n",
    "  \n",
    "            # 写入所有评论到文件  \n",
    "                for comment in comments_:  \n",
    "                    f_all_comments.write(comment.text.strip() + '\\n')  \n",
    "  \n",
    "            print(f\"电影《{url[1]}》的影评爬取完毕\")  \n",
    "            time.sleep(5)  \n",
    "print(\"所有电影的影评已爬取并保存至all_movie_comments.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences have been written to C:/Users/86187/Desktop/yingpin/sbd.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file_path = 'C:/Users/86187/Desktop/yingpin/all_movie_comments.txt'  \n",
    "# 输出文件的路径  \n",
    "output_file_path = 'C:/Users/86187/Desktop/yingpin/sbd.txt'  \n",
    "  \n",
    "with open(input_file_path, 'r', encoding='utf-8') as input_file:  \n",
    "    content = input_file.read()  \n",
    "  \n",
    "# 使用简单的句号（.）作为分隔符进行分割  \n",
    "# 注意：这种方法不会处理缩写、小数点后的数字等情况  \n",
    "sentences = content.split('。')  \n",
    "  \n",
    "# 过滤掉空字符串，并去除可能存在的换行符或空格  \n",
    "sentences = [sentence.strip() for sentence in sentences if sentence.strip()]  \n",
    "  \n",
    "# 使用 with 语句打开输出文件，并将每个句子写入新文件  \n",
    "with open(output_file_path, 'w', encoding='utf-8') as output_file:  \n",
    "    for sentence in sentences:  \n",
    "        output_file.write(sentence + '.\\n')  # 每个句子后添加句号和换行符  \n",
    "  \n",
    "# 现在 output_simple.txt 文件包含了按句号分割后的一行一句的文本  \n",
    "print(f\"Sentences have been written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences with sentiment labels have been written to C:/Users/86187/Desktop/yingpin/fenl.txt\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob  \n",
    "  \n",
    "# 假设你的txt文件路径是 'input.txt'  \n",
    "input_file_path = 'C:/Users/86187/Desktop/yingpin/sbd.txt'  \n",
    "# 输出文件的路径，用于存储带有标签的文本  \n",
    "output_file_path = 'C:/Users/86187/Desktop/yingpin/fenl.txt'  \n",
    "  \n",
    "# 读取txt文件  \n",
    "with open(input_file_path, 'r', encoding='utf-8') as file:  \n",
    "    lines = file.readlines()  \n",
    "  \n",
    "# 初始化一个列表来存储带有标签的文本  \n",
    "labeled_lines = []  \n",
    "  \n",
    "# 遍历每一行文本并进行情感分析  \n",
    "for line in lines:  \n",
    "    # 去除每行末尾的换行符  \n",
    "    sentence = line.strip()  \n",
    "      \n",
    "    # 使用TextBlob进行情感分析  \n",
    "    blob = TextBlob(sentence)  \n",
    "      \n",
    "    # 根据polarity判断情感标签，这里假设polarity > 0为正面情感，否则为负面情感  \n",
    "    # 你可以根据自己的需求调整这个阈值  \n",
    "    if blob.sentiment.polarity > -0.005:  \n",
    "        sentiment_label = 1  # 好的  \n",
    "    else:  \n",
    "        sentiment_label = 0  # 坏的  \n",
    "      \n",
    "    # 将带有标签的文本添加到列表中，标签在句子的前面，以逗号分隔  \n",
    "    labeled_lines.append(f\"{sentiment_label},{sentence}\\n\")  \n",
    "  \n",
    "# 将带有标签的文本写入到新的txt文件中  \n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:  \n",
    "    file.writelines(labeled_lines)  \n",
    "  \n",
    "print(f\"Sentences with sentiment labels have been written to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  \n",
    "  \n",
    "# 步骤1：读取txt文件  \n",
    "with open('C:/Users/86187/Desktop/yingpin/fenl.txt', 'r', encoding='utf-8') as file:  \n",
    "    lines = file.readlines()  \n",
    "  \n",
    "# 步骤2：随机划分数据  \n",
    "train_ratio = 0.8  # 假设80%的数据作为训练集，剩下的20%作为测试集  \n",
    "train_size = int(len(lines) * train_ratio)  \n",
    "  \n",
    "# 打乱数据顺序  \n",
    "random.shuffle(lines)  \n",
    "  \n",
    "# 划分训练集和测试集  \n",
    "train_lines = lines[:train_size]  \n",
    "test_lines = lines[train_size:]  \n",
    "  \n",
    "# 步骤3：写入训练集和测试集  \n",
    "with open('C:/Users/86187/Desktop/yingpin/train_data.txt', 'w', encoding='utf-8') as train_file:  \n",
    "    train_file.writelines(train_lines)  \n",
    "with open('C:/Users/86187/Desktop/yingpin/test_data.txt', 'w', encoding='utf-8') as test_file:  \n",
    "    test_file.writelines(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_corpus, stopwords\n",
    "\n",
    "TRAIN_PATH = \"C:/Users/86187/Desktop/yingpin/train_data.txt\"\n",
    "TEST_PATH = \"C:/Users/86187/Desktop/yingpin/test_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别加载训练集和测试集\n",
    "train_data = load_corpus(TRAIN_PATH)\n",
    "test_data = load_corpus(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>角色 的 设置 尤其 是 辨识 度 很 高 的 蛇蝎美人 演员 的 表演 有 一种 醇厚 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>全片 最討厭 的 就是 男主 為 了 錢 留下 來 享受 著 一切 卻 又 背後說 人 傻 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>看来 宁浩学盖 里奇 而盖 里奇 就学 的 这部 吧 影响 了 太 多 的 后来者 经典 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>不知 为何 有 看 公民 凯恩 的 感觉 故事 十分 精彩 算是 关于 电影 电影 人 的 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>xiami com song 暂无 他话 今年 电影节 完美 落幕</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  角色 的 设置 尤其 是 辨识 度 很 高 的 蛇蝎美人 演员 的 表演 有 一种 醇厚 的...\n",
       "1      1  全片 最討厭 的 就是 男主 為 了 錢 留下 來 享受 著 一切 卻 又 背後說 人 傻 ...\n",
       "2      1  看来 宁浩学盖 里奇 而盖 里奇 就学 的 这部 吧 影响 了 太 多 的 后来者 经典 的...\n",
       "3      1  不知 为何 有 看 公民 凯恩 的 感觉 故事 十分 精彩 算是 关于 电影 电影 人 的 ...\n",
       "4      1                  xiami com song 暂无 他话 今年 电影节 完美 落幕"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.DataFrame(train_data, columns=[\"label\",\"text\"])\n",
    "df_test = pd.DataFrame(test_data, columns=[\"label\",\"text\"])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [角色, 的, 设置, 尤其, 是, 辨识, 度, 很, 高, 的, 蛇蝎美人, 演员, 的...\n",
       "1    [全片, 最討厭, 的, 就是, 男主, 為, 了, 錢, 留下, 來, 享受, 著, 一切...\n",
       "2    [看来, 宁浩学盖, 里奇, 而盖, 里奇, 就学, 的, 这部, 吧, 影响, 了, 太,...\n",
       "3    [不知, 为何, 有, 看, 公民, 凯恩, 的, 感觉, 故事, 十分, 精彩, 算是, ...\n",
       "4          [xiami, com, song, 暂无, 他话, 今年, 电影节, 完美, 落幕]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_input = df_train['text'].map(lambda s: s.split(\" \"))   # [for w in s.split(\" \") if w not in stopwords]\n",
    "wv_input.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "\n",
    "# Word2Vec\n",
    "word2vec = models.Word2Vec(wv_input, \n",
    "                           vector_size=64,   # 词向量维度\n",
    "                           min_count=1,      # 最小词频, 因为数据量较小, 这里卡1\n",
    "                           epochs=1000)      # 迭代轮次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('昆汀', 0.40840768814086914),\n",
       " ('自己', 0.3936082422733307),\n",
       " ('往往', 0.38563862442970276),\n",
       " ('说话', 0.38517770171165466),\n",
       " ('尽管如此', 0.350215345621109),\n",
       " ('人', 0.330673485994339),\n",
       " ('挚爱', 0.32277801632881165),\n",
       " ('男演员', 0.31703656911849976),\n",
       " ('不能', 0.3166625201702118),\n",
       " ('要', 0.3158951699733734)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"你\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
